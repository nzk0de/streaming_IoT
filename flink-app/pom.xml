<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>com.flink_app</groupId>
    <artifactId>flink-java-sensor-app</artifactId>
    <version>1.0-SNAPSHOT</version>
    <packaging>jar</packaging>

    <name>Flink Java Sensor App</name>

    <properties>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <java.version>17</java.version>
        <flink.version>1.19.2</flink.version>
        <!-- Keep flink.connector.kafka.version if it's specifically tested/required -->
        <!-- Otherwise, often aligning with flink.version for flink-connector-kafka is fine -->
        <!-- <flink.connector.kafka.version>${flink.version}</flink.connector.kafka.version> -->
        <scala.binary.version>2.12</scala.binary.version>
        <slf4j.version>2.0.12</slf4j.version>
        <log4j.version>2.23.1</log4j.version>
        <jackson.version>2.14.2</jackson.version> <!-- Flink 1.19 uses Jackson 2.15.2, consider aligning -->
        <onnxruntime.version>1.17.3</onnxruntime.version>
        <mlflow.client.version>2.13.0</mlflow.client.version>
        <maven.compiler.source>${java.version}</maven.compiler.source>
        <maven.compiler.target>${java.version}</maven.compiler.target>
        <hadoop.version>3.3.6</hadoop.version> <!-- Or a version compatible with Flink's S3 shaded Hadoop -->
        <aws.java.sdk.s3.version>1.12.551</aws.java.sdk.s3.version> <!-- Or a recent compatible version -->
    </properties>

    <dependencies>
        <!-- Flink Core -->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-streaming-java</artifactId>
            <version>${flink.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-clients</artifactId>
            <version>${flink.version}</version>
            <scope>provided</scope>
        </dependency>

        <!-- Flink Kafka Connector -->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-connector-kafka</artifactId>
            <!-- Using your specified version -->
            <version>3.3.0-1.19</version>
        </dependency>
        <!-- flink-connector-base is a transitive dependency of flink-connector-kafka -->
        <!-- No need to declare it explicitly unless for a specific version override -->

        <!-- Jackson for JSON processing -->
        <dependency>
            <groupId>com.fasterxml.jackson.core</groupId>
            <artifactId>jackson-databind</artifactId>
            <version>${jackson.version}</version>
        </dependency>
        <dependency>
            <groupId>com.fasterxml.jackson.datatype</groupId>
            <artifactId>jackson-datatype-jsr310</artifactId>
            <version>${jackson.version}</version>
        </dependency>

        <!-- ONNX Runtime -->
        <dependency>
            <groupId>com.microsoft.onnxruntime</groupId>
            <artifactId>onnxruntime</artifactId>
            <version>${onnxruntime.version}</version>
        </dependency>
    <dependency>
        <groupId>org.apache.parquet</groupId>
        <artifactId>parquet-avro</artifactId>
        <version>1.12.0</version>
    </dependency>
        <!-- MLflow Client -->
        <dependency>
            <groupId>org.mlflow</groupId>
            <artifactId>mlflow-client</artifactId>
            <version>${mlflow.client.version}</version>
            <exclusions>
                <exclusion>
                    <groupId>org.apache.httpcomponents</groupId>
                    <artifactId>httpclient</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.apache.httpcomponents</groupId>
            <artifactId>httpclient</artifactId>
            <version>4.5.14</version>
        </dependency>

        <!-- Flink S3 Filesystem Connector (Hadoop variant is usually preferred) -->
        <!-- This is already downloaded in your Dockerfile, but for local dev/testing -->
        <!-- and to ensure classpath, it's good to have it. -->
        <!-- If you rely SOLELY on the Dockerfile download, scope can be 'provided' -->
        <!-- but for `flink-connector-files` and `flink-parquet`, you need them compiled against. -->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-s3-fs-hadoop</artifactId>
            <version>${flink.version}</version>
            <scope>provided</scope>
        </dependency>

        <!-- Flink Table API -->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-table-api-java-bridge</artifactId>
            <version>${flink.version}</version>
            <scope>provided</scope> <!-- Flink runtime provides this -->
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-table-planner-loader</artifactId>
            <version>${flink.version}</version>
            <scope>provided</scope> <!-- Flink runtime provides this -->
        </dependency>
        <!-- No need for flink-table-runtime explicitly, it's pulled by api-java-bridge -->

        <!-- Flink Filesystem Connector (for 'filesystem' connector in Table API) -->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-connector-files</artifactId>
            <version>${flink.version}</version>
            <!-- Not 'provided' as your Table API code will directly use it -->
        </dependency>

        <!-- Flink Parquet Format -->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-parquet</artifactId>
            <version>${flink.version}</version>
            <!-- Not 'provided' for the same reason -->
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-avro</artifactId>
            <version>1.13.6</version>
        </dependency>
        <!-- Hadoop AWS for S3A FileSystem (used by flink-connector-files with s3a:// paths) -->
        <!-- Flink's flink-s3-fs-hadoop bundles a shaded version of this. -->
        <!-- However, if flink-connector-files needs direct access or specific version, -->
        <!-- it might be necessary. Given you download flink-s3-fs-hadoop separately in Docker, -->
        <!-- this might primarily be for local dev or ensuring consistent versions. -->
        <!-- Let's exclude it for now to rely on Flink's shaded version from flink-s3-fs-hadoop -->
        <!--
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-aws</artifactId>
            <version>${hadoop.version}</version>
        </dependency>
        <dependency>
            <groupId>com.amazonaws</groupId>
            <artifactId>aws-java-sdk-s3</artifactId>
            <version>${aws.java.sdk.s3.version}</version>
        </dependency>
        -->
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-client</artifactId>
            <version>${hadoop.version}</version> <!-- Your hadoop.version is 3.3.6 -->
            <!-- Default scope is compile, so it's included in the fat JAR -->
            <exclusions>
                <exclusion>
                    <groupId>org.slf4j</groupId>
                    <artifactId>slf4j-log4j12</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>log4j</groupId>
                    <artifactId>log4j</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.google.guava</groupId>
                    <artifactId>guava</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>org.eclipse.jetty</groupId>
                    <artifactId>*</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <!-- Logging -->
        <dependency>
            <groupId>org.apache.logging.log4j</groupId>
            <artifactId>log4j-slf4j-impl</artifactId>
            <version>${log4j.version}</version>
            <scope>runtime</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.logging.log4j</groupId>
            <artifactId>log4j-api</artifactId>
            <version>${log4j.version}</version>
            <scope>runtime</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.logging.log4j</groupId>
            <artifactId>log4j-core</artifactId>
            <version>${log4j.version}</version>
            <scope>runtime</scope>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>3.11.0</version>
                <configuration>
                    <source>${java.version}</source>
                    <target>${java.version}</target>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-shade-plugin</artifactId>
                <version>3.5.1</version>
                <executions>
                    <execution>
                        <phase>package</phase>
                        <goals>
                            <goal>shade</goal>
                        </goals>
                        <configuration>
                            <artifactSet>
                                <excludes>
                                    <exclude>org.apache.flink:flink-shaded-*</exclude>
                                    <exclude>org.slf4j:slf4j-api</exclude>
                                    <exclude>org.apache.logging.log4j:log4j-slf4j-impl</exclude>
                                    <exclude>org.apache.logging.log4j:log4j-api</exclude>
                                    <exclude>org.apache.logging.log4j:log4j-core</exclude>
                                    <!-- Provided Flink dependencies -->
                                    <exclude>org.apache.flink:flink-streaming-java</exclude>
                                    <exclude>org.apache.flink:flink-clients</exclude>
                                    <exclude>org.apache.flink:flink-table-api-java-bridge</exclude>
                                    <exclude>org.apache.flink:flink-table-planner-loader</exclude>
                                    <!-- Exclude flink-s3-fs-hadoop if it's always in Flink's plugin dir -->
                                    <!-- <exclude>org.apache.flink:flink-s3-fs-hadoop</exclude> -->
                                </excludes>
                            </artifactSet>
                            <filters>
                                <filter>
                                    <artifact>*:*</artifact>
                                    <excludes>
                                        <exclude>META-INF/*.SF</exclude>
                                        <exclude>META-INF/*.DSA</exclude>
                                        <exclude>META-INF/*.RSA</exclude>
                                    </excludes>
                                </filter>
                            </filters>
                            <transformers>
                                <transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer">
                                    <mainClass>com.flink_app.FlinkJavaJob</mainClass>
                                </transformer>
                                <transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer"/>
                            </transformers>
                            <createDependencyReducedPom>false</createDependencyReducedPom>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>
</project>