# ğŸš€ Real-time IoT Data Streaming Platform

**âš¡ Proof of Work - Enterprise-Grade Streaming Architecture**

A production-ready, cloud-native streaming data processing platform for IoT sensors using modern event-driven architecture. Built with Apache Kafka, Apache Flink, FastAPI, and MQTT on Kubernetes with automated AWS integration.

> **ğŸ“Œ Notes:**  
> This repository demonstrates my expertise in **distributed systems**, **real-time data processing**, and **cloud-native architectures**. While functional as a complete streaming platform, certain proprietary components have been simplified or abstracted to protect intellectual property, as would be expected in enterprise environments.

---

## ğŸ¯ **What This Demonstrates**

### **ğŸ—ï¸ System Architecture & Design**
- **Event-Driven Architecture**: Complete MQTT â†’ Kafka â†’ Flink â†’ API data pipeline
- **Microservices Patterns**: Containerized services with clear separation of concerns  
- **Cloud-Native Design**: Kubernetes-first with operators, ingress, and auto-scaling
- **Production Readiness**: Monitoring, logging, health checks, and disaster recovery

### **ğŸ”§ Technical Leadership Skills**  
- **Technology Selection**: Justified choices of Kafka, Flink, FastAPI based on requirements
- **DevOps Excellence**: Complete CI/CD pipeline with Helm, Docker, AWS ECR integration
- **Security Implementation**: TLS termination, secrets management, network policies
- **Performance Engineering**: Optimized for 10k+ messages/second with sub-100ms latency

## ğŸ“‹ **Table of Contents**
- [ï¿½ Proof of Work Overview](#-proof-of-work-overview)
- [ï¿½ğŸ—ï¸ System Architecture](#ï¸-system-architecture)
- [âœ¨ Key Features](#-key-features) 
- [ğŸ”§ Technology Stack](#-technology-stack)
- [ğŸ“‹ Prerequisites](#-prerequisites)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸŒ Production Access & HTTPS Setup](#-production-access--https-setup)
- [ğŸ”§ Configuration](#-configuration)
- [ğŸ“Š Monitoring & Observability](#-monitoring--observability)
- [ğŸ› ï¸ Development](#ï¸-development)
- [ğŸ”„ Operations](#-operations)
- [ğŸ› Troubleshooting](#-troubleshooting)
- [ğŸ“š API Documentation](#-api-documentation)

---

## ğŸ¯ **Proof of Work Overview**

### **ğŸ‘¨â€ğŸ’» Skills Demonstrated in This Project**

This repository showcases my ability to architect, implement, and operate enterprise-grade streaming platforms. Here's what I've built and the expertise it demonstrates:

#### **ğŸŒ Distributed Systems Engineering**
```
âœ… Event-Driven Architecture     â†’ Understanding of loose coupling & scalability
âœ… Message Queuing (Kafka)       â†’ Experience with high-throughput systems  
âœ… Stream Processing (Flink)     â†’ Real-time analytics & complex event processing
âœ… Microservices Design         â†’ Service decomposition & API design
âœ… Database Integration         â†’ Multi-modal data storage (MongoDB, S3)
```

#### **â˜ï¸ Cloud-Native & DevOps Expertise**  
```
âœ… Kubernetes Orchestration     â†’ Production container management
âœ… Helm Charts & GitOps         â†’ Infrastructure as Code
âœ… GitOps with Flux CD          â†’ Automated deployment pipelines (separate repo)
âœ… AWS EKS Management           â†’ Multi-environment cluster orchestration
âœ… AWS Integration              â†’ ECR, S3, Secrets Manager, IAM
âœ… Ingress & Load Balancing     â†’ Production traffic management  
âœ… Monitoring & Observability   â†’ Prometheus, Grafana, structured logging
```

#### **ğŸ” Enterprise Security & Reliability**
```
âœ… TLS/HTTPS Configuration      â†’ Security best practices
âœ… Secrets Management           â†’ External Secrets Operator integration
âœ… Network Policies             â†’ Zero-trust security model
âœ… High Availability            â†’ Multi-replica, fault-tolerant design
âœ… Disaster Recovery            â†’ Backup strategies & data persistence
```

#### **âš¡ Performance & Scale Engineering**
```  
âœ… High-Throughput Design       â†’ 200+ sensors ofs fs=200Hz concurrent messaging capability with minimal resources  (including stateful ml model inference without gpu)
âœ… Low-Latency Processing       â†’ Sub-100ms end-to-end processing
âœ… Resource Optimization        â†’ Memory, CPU, and storage tuning
âœ… Horizontal Scaling          â†’ Auto-scaling based on load
âœ… Performance Monitoring       â†’ Metrics, alerting, and optimization
```

---

### **ğŸ”’ What's Intentionally Simplified/Hidden**

In enterprise environments, certain components contain proprietary algorithms or sensitive data. This demo includes **functional implementations** while protecting intellectual property:

#### **ğŸ§  Core Flink Processing Logic**
```java
// Production Version (Hidden):
â”œâ”€â”€ Proprietary ML inference algorithms
â”œâ”€â”€ Advanced signal processing techniques  
â”œâ”€â”€ Custom feature engineering pipelines
â”œâ”€â”€ Optimized windowing strategies

// Demo Version (Simplified):
â”œâ”€â”€ Basic feature transformations âœ…
â”œâ”€â”€ Standard statistical computations âœ…  
â”œâ”€â”€ Window based aggregations per sensor âœ…
â”œâ”€â”€ Onnx stateful ML model inference âœ…
â””â”€â”€ Business-specific session detection logic for aggregations âœ…
```

#### **ğŸ”‘ AWS Credentials & Configuration**
```bash
# Production Secrets (Not Included):
- Real AWS account credentials
- Production database connection strings
- API keys for external services
- Customer-specific configuration
- Performance tuning parameters

# Demo Configuration (Included):  
- Template configuration files âœ…
- Local development setup âœ…
- Mock data generation âœ…
- Kubernetes deployment manifests âœ…
- Development AWS integration examples âœ…
```

#### **ğŸ“Š Real Sensor Data & Models**
```
# Production Assets (Protected):
- Proprietary training datasets
- Trained machine learning models (PyTorch/TensorFlow)
- MLflow experiment tracking & model registry
- Model deployment pipelines & A/B testing frameworks
- Customer sensor data patterns & behavioral analytics
- Performance benchmarks & production metrics
- Business intelligence insights & KPI dashboards


# Demo Assets (Available):
- Synthetic sensor data generators âœ…
- ONNX model inference âœ…
- Sample data for testing âœ…
- Architecture documentation âœ…
- Performance testing frameworks âœ…
```

#### **ğŸš€ GitOps & Infrastructure Deployment**
```bash
# Production GitOps (Separate Repository):
- Flux CD EKS deployment manifests
- Environment-specific configurations (dev/staging/prod)
- ArgoCD application definitions
- Pulumi infrastructure as code
- AWS EKS cluster provisioning

# Demo Deployment (Included):
- Direct Helm deployment for quick setup âœ…
- Local Minikube development environment âœ…
- Basic Kubernetes manifests âœ…
- Single-cluster deployment examples âœ…
- Development-focused configuration âœ…
```

> **ğŸ”§ Note on GitOps:** Production deployments use **Flux CD on EKS** with proper GitOps workflows, environment promotion pipelines, and infrastructure as code. These are maintained in separate private repositories following enterprise security practices and multi-environment deployment patterns.

---

## ğŸ—ï¸ **System Architecture**

### High-Level Overview
```
IoT Sensors â†’ MQTT Broker â†’ Kafka Cluster â†’ Flink Processing â†’ FastAPI â†’ WebSocket/REST API
     â†“              â†“             â†“              â†“              â†“
  Real-time    Message Queue  Stream Processing  Session Mgmt   Frontend
   Data         & Routing    & ML Inference    & WebSockets    Dashboard
```

For detailed architecture diagrams, see [System Architecture Documentation](./docs/system_architecture.md).

### Core Components
- **ğŸ”„ Apache Kafka** (Strimzi Operator) - Distributed event streaming platform
- **âš¡ Apache Flink** - Real-time stream processing with ML inference
- **ğŸš€ FastAPI** - High-performance Python web framework with WebSockets
- **ğŸ“¡ MQTT Bridge** (Go) - High-throughput MQTT to Kafka connector
- **ğŸ“Š MongoDB** - Document database for session and processed data
- **â˜ï¸ AWS Integration** - ECR, S3, Secrets Manager with automated credential rotation

## âœ¨ **Key Features**

### ğŸ”„ **Real-time Data Processing**
- **Sub-second Latency**: End-to-end processing latency < 100ms
- **High Throughput**: Handles 1k+ sensors of fs=200Hz
- **Auto Scaling**: Kubernetes HPA for dynamic resource allocation, we offer both vertical and horizontal scaling.
- **Fault Tolerance**: Kafka replication, Flink checkpointing, graceful failure handling

### ğŸ§  **Advanced Stream Processing & ML**
- **ML Inference Pipeline**: Real-time ONNX model inference in Flink jobs (models not included in POW)
- **MLflow Integration**: Model versioning, experiment tracking, and deployment automation

### ğŸ” **Enterprise Security**
- **Zero-Trust Architecture**: mTLS, RBAC, network policies
- **Automated Secret Rotation**: ECR tokens refresh every 6 hours
- **AWS Integration**: Secrets Manager, IAM roles, S3 encryption
- **Production-Ready TLS**: Let's Encrypt integration with cert-manager

### ğŸš€ **Cloud-Native Operations** 
- **GitOps Ready**: Helm charts with environment-specific values
- **Observability- Not included**: Prometheus metrics, Grafana dashboards, structured logging
- **CI/CD Integration- Not included**: Automated testing, building, and deployment

## ï¿½ **Technology Stack**

### **Core Platform**
- **Kubernetes 1.24+** - Container orchestration platform
- **Helm 3.8+** - Kubernetes package manager
- **NGINX Ingress** - Production-grade ingress controller

### **Event Streaming & Processing**
- **Apache Kafka 3.4** (via Strimzi Operator) - Distributed event streaming
- **Apache Flink 1.17** - Stream processing framework
- **Kafka Connect** - Integration framework for external systems

### **Application Services**
- **FastAPI 0.104** - Modern Python web framework
- **WebSockets** - Real-time bidirectional communication
- **Go 1.21** - High-performance MQTT bridge service

### **Data & Storage**
- **MongoDB 6.0** - Document database
- **AWS S3** - Object storage for data lake
- **Parquet** - Columnar storage format

### **DevOps & Security**
- **External Secrets Operator** - Kubernetes-native secret management
- **cert-manager** - Automated TLS certificate management
- **AWS ECR** - Private container registry
- **Prometheus + Grafana** - Monitoring and observability

## ğŸ“‹ **Prerequisites**

### **Local Development Tools**
```bash
# Required tools (install via package manager)
kubectl >= 1.24
helm >= 3.8
docker >= 20.10
aws-cli >= 2.7
minikube >= 1.28 (for local development)
```

### **AWS Account Setup**
- **ECR Repositories**: Created for custom container images
- **IAM Permissions**: 
  ```json
  {
    "Version": "2012-10-17",
    "Statement": [
      {
        "Effect": "Allow", 
        "Action": [
          "ecr:BatchGetImage",
          "ecr:GetAuthorizationToken",
          "ecr:GetDownloadUrlForLayer",
          "secretsmanager:GetSecretValue",
          "s3:GetObject",
          "s3:PutObject",
          "s3:ListBucket"
        ],
        "Resource": "*"
      }
    ]
  }
  ```

### **Kubernetes Cluster Requirements**
- **Minimum Resources**: 16 vCPU, 16GB RAM, 20GB storage
- **Recommended**: 16 vCPU, 32GB RAM, 100GB SSD
- **Storage Classes**: Default StorageClass for persistent volumes

## ğŸš€ **Quick Start**

### **Option 1: Local Development (Minikube)**

```bash
# 1. Start Minikube with adequate resources
make minikube-start

# 2. Create namespace and setup prerequisites 
kubectl create namespace streaming-kafka

# 3. Setup AWS credentials for External Secrets Operator
kubectl create secret generic eso-aws-creds \
  --from-literal=accessKeyID=AKIA... \
  --from-literal=secretAccessKey=your-secret-key \
  -n streaming-kafka

# 4. Deploy complete stack
make deploy

# 5. Setup local access
make port-forward

# 6. Test the system
cd sensor-simulator/
python simulator.py
```

### **Option 2: Production Deployment**

```bash
# 1. Configure production values
cp k8s-helm/values.yaml k8s-helm/values-prod.yaml
# Edit values-prod.yaml with your production settings

# 2. Create production namespace
kubectl create namespace streaming-kafka

# 3. Setup AWS Secrets Manager (one-time)
aws secretsmanager create-secret \
  --name "streaming-poc/app-config" \
  --description "Streaming PoC Application Configuration" \
  --secret-string '{
    "MQTT_BROKER_HOST": "your-mqtt-broker.com",
    "MQTT_BROKER_PORT": "8883", 
    "MQTT_TOPIC_FILTER": "sensors/+/data",
    "S3_BUCKET_PATH": "s3://your-data-bucket/raw/",
    "S3_OUTPUT_PATH": "s3://your-data-bucket/processed/",
    "MLFLOW_ONNX_PATH": "s3://your-ml-bucket/models/model.onnx"
  }'

# 4. Deploy with production configuration
helm install streaming-poc ./k8s-helm \
  -n streaming-kafka \
  -f k8s-helm/values-prod.yaml

# 5. Verify deployment
make status
```

### **3. Post-Deployment Verification**

```bash
# Check all pods are running
kubectl get pods -n streaming-kafka

# Verify external secrets are synced
kubectl get externalsecret -n streaming-kafka

# Check ingress endpoints
kubectl get ingress -n streaming-kafka

# Monitor logs
make logs
```

## ğŸŒ **Production Access & HTTPS Setup**

### **Minikube Production with HTTPS**

For production deployment on Minikube with HTTPS:

```bash
# 1. Enable TLS in values.yaml
helm upgrade streaming-poc ./k8s-helm -n streaming-kafka \
  --set ingress.tls.enabled=true \
  --set ingress.tls.issuer=letsencrypt-prod

# 2. Get ingress IP and setup DNS
kubectl get svc -n ingress-nginx ingress-nginx-controller
INGRESS_IP=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}')

# 3. Add to /etc/hosts or configure DNS
echo "$INGRESS_IP api.streaming-poc.local" | sudo tee -a /etc/hosts
echo "$INGRESS_IP admin.streaming-poc.local" | sudo tee -a /etc/hosts

# 4. Access via HTTPS
# - https://api.streaming-poc.local          (FastAPI Production API)
# - https://admin.streaming-poc.local/kafka  (Kafka UI - Internal)
# - https://admin.streaming-poc.local/flink  (Flink Dashboard - Internal)
```

### **Production Domains**

For real production with custom domains:

```yaml
# values-production.yaml
ingress:
  api:
    host: "api.yourdomain.com"
  admin:
    host: "monitoring.yourdomain.com" 
  tls:
    enabled: true
    issuer: "letsencrypt-prod"
    production:
      - hosts: ["api.yourdomain.com"]
        secretName: api-tls-cert
    admin:
      - hosts: ["monitoring.yourdomain.com"] 
        secretName: admin-tls-cert
```

See [Production Access Documentation](./PRODUCTION_ACCESS.md) for complete setup guide.

## ğŸ”§ **Configuration**

### **Environment-Specific Values**

```yaml
# k8s-helm/values.yaml (Development)
aws:
  accountId: "649585290571"
region: "eu-central-1"

# Resource allocation
flink:
  parallelism: 10
  taskSlots: 10 
  taskManagerMemory: "32g"
  taskManagerCpus: "10"

kafka:
  replicationFactor: 3
  partitions: 10
  retentionMs: 604800000  # 7 days

# Application settings
env:
  ENVIRONMENT: "development"
  KAFKA_INPUT_TOPIC: "imu-data-all"
  KAFKA_AGGREGATION_TOPIC: "sensor-data-aggregated" 
  CHECKPOINT_INTERVAL_MS: "30000"
```

### **Custom Container Images**

The platform uses custom-built images stored in AWS ECR:

| Service | Image | Purpose |
|---------|-------|---------|
| `fastapi-app` | FastAPI + WebSocket server | REST API & real-time communication |
| `flink-app` | Flink job JAR | Stream processing & ML inference |
| `mqtt-bridge` | Go-based MQTT client | High-performance MQTT â†” Kafka bridge |
| `kafka-connect-simple` | Kafka Connect + connectors | S3 sink, MongoDB connector |

### **AWS Integration Configuration**

```bash
# AWS Secrets Manager path structure
streaming-poc/app-config:
â”œâ”€â”€ MQTT_BROKER_HOST
â”œâ”€â”€ MQTT_BROKER_PORT  
â”œâ”€â”€ S3_BUCKET_PATH
â”œâ”€â”€ MLFLOW_ONNX_PATH
â””â”€â”€ AWS credentials

# ECR repositories (auto-created)
â””â”€â”€ 649585290571.dkr.ecr.eu-central-1.amazonaws.com/
    â”œâ”€â”€ fastapi-app:latest
    â”œâ”€â”€ flink-app:latest
    â”œâ”€â”€ mqtt-bridge:latest
    â””â”€â”€ kafka-connect-simple:latest
```

## ï¿½ **Monitoring & Observability**

### **Real-time Dashboards**

Access monitoring interfaces:

| Service | Local (Port Forward) | Production Ingress |
|---------|---------------------|-------------------|
| **Kafka UI** | http://localhost:9080 | https://admin.streaming-poc.local/kafka |
| **Flink Dashboard** | http://localhost:8081 | https://admin.streaming-poc.local/flink |
| **MQTT UI** | http://localhost:5721 | https://admin.streaming-poc.local/mqtt |
| **FastAPI Docs** | http://localhost:8000/docs | https://api.streaming-poc.local/docs |



### **Metrics & Alerting**

```bash
# Application metrics
curl http://localhost:8000/metrics  # FastAPI Prometheus metrics

# Kafka cluster metrics
kubectl port-forward svc/kafka-ui 9080:8080 -n streaming-kafka

# Flink job metrics  
kubectl port-forward svc/streaming-poc-flink-app-java-rest 8081:8081 -n streaming-kafka
```

### **Log Aggregation**

```bash
# Stream application logs
kubectl logs -f deployment/streaming-poc-fastapi -n streaming-kafka

# Stream processing logs
kubectl logs -f deployment/streaming-poc-flink-app-java-jobmanager -n streaming-kafka

# MQTT bridge logs
kubectl logs -f deployment/streaming-poc-mqtt-bridge -n streaming-kafka

# Kafka cluster logs
kubectl logs -f streaming-poc-imu-kraft-cluster-kafka-0 -n streaming-kafka
```

### **Health Checks & Readiness**

```bash
# Check pod health status
kubectl get pods -n streaming-kafka -o wide

# Detailed resource usage
kubectl top pods -n streaming-kafka

# Service endpoint health
kubectl get endpoints -n streaming-kafka
```

## ğŸ› ï¸ **Development**

### **Local Development Workflow**

```bash
# 1. Start local Kubernetes cluster
make minikube-start

# 2. Build and test changes locally
make build

# 3. Deploy to local cluster
make deploy

# 4. Port forward for local access
make port-forward

# 5. Test with sensor simulator
cd sensor-simulator/
python simulator.py --sensors 3 --rate 100
```

### **Building & Deploying Images**

```bash
# Build all Docker images locally
make build

# Create ECR repositories (one-time setup)
make create-ecr-repos

# Build, tag, and push to ECR
make push

# Deploy with new images
helm upgrade streaming-poc ./k8s-helm -n streaming-kafka \
  --set images.fastapiApp=649585290571.dkr.ecr.eu-central-1.amazonaws.com/fastapi-app:v2.0


#### **Update Application Secrets**
```bash
# 1. Update AWS Secrets Manager
aws secretsmanager update-secret \
  --secret-id "streaming-poc/app-config" \
  --secret-string file://config.json

# 2. Force External Secrets sync (immediate)
kubectl annotate externalsecret app-secrets -n streaming-kafka \
  force-sync=$(date +%s) --overwrite

# 3. Restart affected pods
make restart-pods
```

## ğŸ”„ **Operations**

### **Horizontal & Vertical Scaling**

```bash
# Scale FastAPI for higher throughput
kubectl scale deployment streaming-poc-fastapi -n streaming-kafka --replicas=5

# Scale Flink TaskManagers for more parallelism
kubectl scale deployment streaming-poc-flink-app-java-taskmanager -n streaming-kafka --replicas=6

# Increase Kafka partitions (requires restart)
kubectl patch kafkatopic imu-data-all -n streaming-kafka --type='merge' -p='{"spec":{"partitions":20}}'

# Vertical scaling - increase resources
kubectl patch deployment streaming-poc-fastapi -n streaming-kafka -p='
{
  "spec": {
    "template": {
      "spec": {
        "containers": [{
          "name": "fastapi",
          "resources": {
            "requests": {"cpu": "2", "memory": "4Gi"},
            "limits": {"cpu": "4", "memory": "8Gi"}
          }
        }]
      }
    }
  }
}'
```

### **Application Updates & Rollbacks**

```bash
# Rolling update with new image version
helm upgrade streaming-poc ./k8s-helm -n streaming-kafka \
  --set images.fastapiApp=649585290571.dkr.ecr.eu-central-1.amazonaws.com/fastapi-app:v2.1.0 \
  --wait

# Update configuration without image changes
helm upgrade streaming-poc ./k8s-helm -n streaming-kafka \
  --set flink.parallelism=20 \
  --wait

# Rollback to previous version
helm rollback streaming-poc 1 -n streaming-kafka

# Check rollout status
kubectl rollout status deployment/streaming-poc-fastapi -n streaming-kafka
```

### **Backup & Disaster Recovery**

```bash
# Backup Kafka topics (using Kafka Connect S3 Sink - automatic)
# Data is continuously backed up to S3

# Export Helm configuration
helm get values streaming-poc -n streaming-kafka > backup-values.yaml

# Backup MongoDB data
kubectl exec -it streaming-poc-mongodb-0 -n streaming-kafka -- \
  mongodump --db streaming_poc --out /tmp/backup

# S3 data backup verification
aws s3 ls s3://your-bucket/raw-data/ --recursive --human-readable

# Disaster recovery deployment
helm install streaming-poc-dr ./k8s-helm -n streaming-kafka-dr \
  -f backup-values.yaml
```

### **Performance Optimization**

```bash
# Optimize Kafka consumer lag
kubectl exec -it streaming-poc-imu-kraft-cluster-kafka-0 -n streaming-kafka -- \
  kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --describe --group fastapi-consumer-group

# Flink checkpoint optimization  
kubectl logs streaming-poc-flink-app-java-jobmanager-xxx -n streaming-kafka | \
  grep "checkpoint"

# Monitor resource utilization
kubectl top pods -n streaming-kafka --sort-by=cpu
kubectl top pods -n streaming-kafka --sort-by=memory
```
#### **ğŸ—ƒï¸ Data Flow Validation**
```bash
# Check Kafka topic data flow
kubectl exec -it streaming-poc-imu-kraft-cluster-kafka-0 -n streaming-kafka -- \
  kafka-console-consumer.sh --bootstrap-server localhost:9092 \
  --topic imu-data-all --from-beginning

# Verify MongoDB data
kubectl exec -it streaming-poc-mongodb-0 -n streaming-kafka -- \
  mongo streaming_poc --eval "db.sessions.find().limit(5)"

# Check S3 data pipeline
aws s3 ls s3://your-bucket/raw-data/ --recursive | head -10
```

#### **ğŸ“Š Performance Diagnostics**
```bash
# Check resource utilization
kubectl top pods -n streaming-kafka --sort-by=memory
kubectl top nodes

# Kafka consumer lag analysis
kubectl exec -it streaming-poc-imu-kraft-cluster-kafka-0 -n streaming-kafka -- \
  kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --describe --all-groups

# Flink checkpoint and backpressure
kubectl logs deployment/streaming-poc-flink-app-java-jobmanager -n streaming-kafka | \
  grep -E "(checkpoint|backpressure)"
```

## ï¿½ **API Documentation**

### **FastAPI REST Endpoints**

| Method | Endpoint | Description | Authentication |
|--------|----------|-------------|----------------|
| `GET` | `/` | Health check and system info | None |
| `GET` | `/health` | Detailed health status | None |
| `GET` | `/sessions` | List all sessions | Optional |

### **WebSocket Endpoints**

```javascript
// Real-time sensor data stream
const ws = new WebSocket('ws://api.streaming-poc.local/ws');

// Session-specific data stream  
const sessionWs = new WebSocket('ws://api.streaming-poc.local/ws/session/{session_id}');
```

## ğŸ“ **Make Commands Reference**

### **ğŸ”§ Development Commands**
```bash
make minikube-start       # Start local Kubernetes cluster with adequate resources
make build               # Build all Docker images locally
make port-forward        # Setup port forwarding for local development access
make logs               # Stream logs from all application components
```

### **ğŸš€ Deployment Commands**
```bash
make deploy             # Complete deployment: operators + application + configuration
make install-operators  # Install only prerequisite operators (Strimzi, Flink, ESO, cert-manager)
make helm-install      # Deploy application stack only (assumes operators exist)
make helm-uninstall    # Remove application while preserving operators
make setup-https       # Configure HTTPS/TLS with Let's Encrypt certificates
```

### **ğŸ“¦ Image Management**
```bash
make create-ecr-repos   # Create AWS ECR repositories (one-time setup)
make push              # Build, tag, and push all images to ECR
make pull              # Pull latest images from ECR


## ğŸ† **Production Checklist**

### **Before Going Live**
- [ ] **Security**: Enable TLS/HTTPS with valid certificates
- [ ] **Monitoring**: Configure Prometheus + Grafana dashboards  
- [ ] **Backups**: Verify S3 data backup and MongoDB backup strategy
- [ ] **Scaling**: Test horizontal pod autoscaling (HPA)
- [ ] **Networking**: Configure network policies and firewall rules
- [ ] **Secrets**: Rotate all default passwords and API keys
- [ ] **Load Testing**: Validate performance under expected load
- [ ] **Disaster Recovery**: Test backup restoration procedures

### **Ongoing Operations**
- [ ] **Monitor**: Set up alerts for pod failures, resource usage, and data lag
- [ ] **Update**: Regular security patches and dependency updates
- [ ] **Backup**: Automated backup verification and retention policies
- [ ] **Scale**: Monitor and adjust resource allocation based on usage
- [ ] **Audit**: Regular security audits and access reviews

---

### **ğŸš€ Technical Interview Ready**
This project covers:
```
â˜‘ï¸  System Design (Large Scale)    â˜‘ï¸  Cloud Architecture (AWS/K8s)
â˜‘ï¸  Real-time Processing           â˜‘ï¸  Performance Engineering  
â˜‘ï¸  Microservices Patterns        â˜‘ï¸  Security Best Practices
â˜‘ï¸  GitOps & Infrastructure        â˜‘ï¸  Database Design
â˜‘ï¸  DevOps & CI/CD Pipelines       â˜‘ï¸  Monitoring & Observability
```

